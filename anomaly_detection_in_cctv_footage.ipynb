{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roshni2020/Anomaly-Detection-in-CCTV-Footage/blob/main/anomaly_detection_in_cctv_footage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ci4NGvjpOqiA",
        "outputId": "b7d22200-7e74-480d-81b0-d73de98526f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Sep 19 02:22:37 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtjzOEmgbh8S"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5mQkC0aX8wi",
        "outputId": "bc36a392-dd43-49ad-bc79-0a7094374989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.19.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.8.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Failed to retrieve file url:\n",
            "\n",
            "\tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses.\n",
            "\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\thttps://drive.google.com/uc?id=1JGrBHwtTZY0wp9EbsQ-uiD5D9QirNaZ6\n",
            "\n",
            "but Gdown can't. Please check connections and permissions.\n",
            "unzip:  cannot find or open /content/DCSASS Dataset.zip, /content/DCSASS Dataset.zip.zip or /content/DCSASS Dataset.zip.ZIP.\n",
            "mv: cannot stat '/content/DCSASS Dataset/Labels': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm -rf /content/*\n",
        "!pip install --upgrade --no-cache-dir gdown\n",
        "# https://drive.google.com/file/d/1JGrBHwtTZY0wp9EbsQ-uiD5D9QirNaZ6/view?usp=sharing\n",
        "!gdown https://drive.google.com/uc?id=1JGrBHwtTZY0wp9EbsQ-uiD5D9QirNaZ6\n",
        "!unzip \"/content/DCSASS Dataset.zip\"\n",
        "!rm -rf \"/content/DCSASS Dataset.zip\"\n",
        "!mv \"/content/DCSASS Dataset/Labels\" /content/Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "89owLbvM_1Vg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def filter_df(path):\n",
        "    df = pd.read_csv(path,names=['file_name', 'label','class'])\n",
        "    df['file_name'] = df['file_name'].apply(lambda x:x+'.mp4')\n",
        "    df = df[df['class'] == 1]\n",
        "    file_names = df['file_name'].unique().tolist()\n",
        "    return file_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "Bk9t9q_2AgFh",
        "outputId": "f543c8b4-1f98-4af6-f31f-9c139e69749c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/DCSASS Dataset'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2908029028.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfile_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/DCSASS Dataset'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "old_folder = os.path.join('/content','DCSASS Dataset')\n",
        "labels_files = os.path.join('/content','Labels')\n",
        "file_paths = {}\n",
        "\n",
        "for i in tqdm(os.listdir(old_folder)):\n",
        "    l1 = os.listdir(os.path.join(old_folder,i))\n",
        "    path = os.path.join(labels_files,i+'.csv')\n",
        "    files = filter_df(path)\n",
        "    file_paths[i] = []\n",
        "    for j in l1:\n",
        "        l2 = os.listdir(os.path.join(old_folder,i,j))\n",
        "        for k in l2:\n",
        "            if k in files:\n",
        "                file_paths[i].append(os.path.join(old_folder,i,j,k))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbAeASy8AN5e"
      },
      "outputs": [],
      "source": [
        "!rm -rf video_data\n",
        "!mkdir video_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Olug5ZniDC3X"
      },
      "outputs": [],
      "source": [
        "new_folder = os.path.join('/content','video_data')\n",
        "th = 50\n",
        "\n",
        "for i,j in tqdm(file_paths.items()):\n",
        "    os.mkdir(os.path.join(new_folder,i))\n",
        "    for idx,k in enumerate(j):\n",
        "        file_name = k.split('/')[-1]\n",
        "        dest_path = os.path.join(new_folder,i,file_name)\n",
        "        os.rename(k,dest_path)\n",
        "        if (idx+1) == th:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7HT24fuKBim"
      },
      "outputs": [],
      "source": [
        "!rm -rf \"/content/DCSASS Dataset\" /content/Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXSQHwImbOaX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import tensorflow as tf\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from moviepy.editor import *\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhksAQXDbPWu"
      },
      "outputs": [],
      "source": [
        "seed_constant = 27\n",
        "np.random.seed(seed_constant)\n",
        "random.seed(seed_constant)\n",
        "tf.random.set_seed(seed_constant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3asbSuOxbqVY"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.figure(figsize = (20, 20))\n",
        "\n",
        "\n",
        "all_classes_names = os.listdir('/content/video_data')\n",
        "\n",
        "random_range = random.sample(range(len(all_classes_names)), 12)\n",
        "\n",
        "for counter, random_index in enumerate(random_range, 1):\n",
        "\n",
        "    selected_class_Name = all_classes_names[random_index]\n",
        "\n",
        "    video_files_names_list = os.listdir(f'/content/video_data/{selected_class_Name}')\n",
        "\n",
        "\n",
        "    selected_video_file_name = random.choice(video_files_names_list)\n",
        "\n",
        "    video_reader = cv2.VideoCapture(f'/content/video_data/{selected_class_Name}/{selected_video_file_name}')\n",
        "\n",
        "    _, bgr_frame = video_reader.read()\n",
        "\n",
        "    video_reader.release()\n",
        "\n",
        "    rgb_frame = cv2.cvtColor(bgr_frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    cv2.putText(rgb_frame, selected_class_Name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "    plt.subplot(5, 4, counter);plt.imshow(rgb_frame);plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qP-zmFfcKUuf"
      },
      "outputs": [],
      "source": [
        "os.listdir('/content/video_data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fm5hESaPbqYF"
      },
      "outputs": [],
      "source": [
        "\n",
        "IMAGE_HEIGHT , IMAGE_WIDTH = 64, 64\n",
        "\n",
        "SEQUENCE_LENGTH = 20\n",
        "\n",
        "DATASET_DIR = \"/content/video_data/\"\n",
        "CLASSES_LIST = ['Robbery',\n",
        " 'Explosion',\n",
        " 'Shoplifting',\n",
        " 'Arrest',\n",
        " 'Fighting',\n",
        " 'RoadAccidents']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esfp6rkYdAkA"
      },
      "outputs": [],
      "source": [
        "def frames_extraction(video_path):\n",
        "\n",
        "    frames_list = []\n",
        "\n",
        "    video_reader = cv2.VideoCapture(video_path)\n",
        "\n",
        "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH), 1)\n",
        "\n",
        "    for frame_counter in range(SEQUENCE_LENGTH):\n",
        "\n",
        "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
        "\n",
        "        success, frame = video_reader.read()\n",
        "\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "\n",
        "        normalized_frame = resized_frame / 255\n",
        "\n",
        "        frames_list.append(normalized_frame)\n",
        "\n",
        "    video_reader.release()\n",
        "\n",
        "    return frames_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QRG17ZpdAmx"
      },
      "outputs": [],
      "source": [
        "def create_dataset():\n",
        "\n",
        "    features = []\n",
        "    labels = []\n",
        "    video_files_paths = []\n",
        "\n",
        "\n",
        "    for class_index, class_name in enumerate(CLASSES_LIST):\n",
        "\n",
        "\n",
        "        print(f'Extracting Data of Class: {class_name}')\n",
        "\n",
        "\n",
        "        files_list = os.listdir(os.path.join(DATASET_DIR, class_name))\n",
        "\n",
        "\n",
        "        for file_name in files_list:\n",
        "\n",
        "          video_file_path = os.path.join(DATASET_DIR, class_name, file_name)\n",
        "\n",
        "          frames = frames_extraction(video_file_path)\n",
        "          if len(frames) == SEQUENCE_LENGTH:\n",
        "            features.append(frames)\n",
        "            labels.append(class_index)\n",
        "            video_files_paths.append(video_file_path)\n",
        "\n",
        "\n",
        "    features = np.asarray(features)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return features, labels, video_files_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BvToG4JdNM9"
      },
      "outputs": [],
      "source": [
        "features, labels, video_files_paths = create_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OPUaZwcoNNH"
      },
      "outputs": [],
      "source": [
        "features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9DGuVOSoQfi"
      },
      "outputs": [],
      "source": [
        "labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwbZXSWxoUqa"
      },
      "outputs": [],
      "source": [
        "video_files_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSNCg9wXdNPy"
      },
      "outputs": [],
      "source": [
        "one_hot_encoded_labels = tf.keras.utils.to_categorical(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGv1uorOdNSc"
      },
      "outputs": [],
      "source": [
        "features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels, test_size = 0.25, shuffle = True, random_state = seed_constant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUAbIPIsdNW8"
      },
      "outputs": [],
      "source": [
        "def create_convlstm_model():\n",
        "\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "\n",
        "    model.add(tf.keras.layers.ConvLSTM2D(filters = 4, kernel_size = (3, 3), activation = 'tanh',data_format = \"channels_last\",\n",
        "                         recurrent_dropout=0.2, return_sequences=True, input_shape = (SEQUENCE_LENGTH,\n",
        "                                                                                      IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n",
        "\n",
        "    model.add(tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n",
        "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.2)))\n",
        "\n",
        "    model.add(tf.keras.layers.ConvLSTM2D(filters = 8, kernel_size = (3, 3), activation = 'tanh', data_format = \"channels_last\",\n",
        "                         recurrent_dropout=0.2, return_sequences=True))\n",
        "\n",
        "    model.add(tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n",
        "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.2)))\n",
        "\n",
        "    model.add(tf.keras.layers.ConvLSTM2D(filters = 14, kernel_size = (3, 3), activation = 'tanh', data_format = \"channels_last\",\n",
        "                         recurrent_dropout=0.2, return_sequences=True))\n",
        "\n",
        "    model.add(tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n",
        "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.2)))\n",
        "\n",
        "    model.add(tf.keras.layers.ConvLSTM2D(filters = 16, kernel_size = (3, 3), activation = 'tanh', data_format = \"channels_last\",\n",
        "                         recurrent_dropout=0.2, return_sequences=True))\n",
        "\n",
        "    model.add(tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n",
        "    #model.add(TimeDistributed(Dropout(0.2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(len(CLASSES_LIST), activation = \"softmax\"))\n",
        "\n",
        "\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    # Return the constructed convlstm model.\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N26sc34gdNZ5"
      },
      "outputs": [],
      "source": [
        "convlstm_model = create_convlstm_model()\n",
        "print(\"Model Created Successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Y9At7MgdNcn"
      },
      "outputs": [],
      "source": [
        "# Plot the structure of the contructed model.\n",
        "tf.keras.utils.plot_model(convlstm_model, to_file = 'convlstm_model_structure_plot.png', show_shapes = True, show_layer_names = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3MaSz6IdNfP"
      },
      "outputs": [],
      "source": [
        "\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 10, mode = 'min', restore_best_weights = True)\n",
        "\n",
        "\n",
        "convlstm_model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
        "\n",
        "# Start training the model.\n",
        "convlstm_model_training_history = convlstm_model.fit(x = features_train, y = labels_train, epochs = 5, batch_size = 4,shuffle = True, validation_split = 0.2, callbacks = [early_stopping_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FT2KkDbcMHYY"
      },
      "outputs": [],
      "source": [
        "model_evaluation_history = convlstm_model.evaluate(features_test, labels_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKIxFp8TMHdK"
      },
      "outputs": [],
      "source": [
        "# Get the loss and accuracy from model_evaluation_history.\n",
        "model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n",
        "\n",
        "# Define the string date format.\n",
        "# Get the current Date and Time in a DateTime Object.\n",
        "# Convert the DateTime object to string according to the style mentioned in date_time_format string.\n",
        "date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
        "current_date_time_dt = dt.datetime.now()\n",
        "current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
        "\n",
        "# Define a useful name for our model to make it easy for us while navigating through multiple saved models.\n",
        "model_file_name = f'convlstm_model_{current_date_time_string}.h5'\n",
        "\n",
        "# Save your Model.\n",
        "convlstm_model.save(model_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoYIexSDMHgy"
      },
      "outputs": [],
      "source": [
        "def plot_metric(model_training_history, metric_name_1, metric_name_2, plot_name):\n",
        "\n",
        "    metric_value_1 = model_training_history.history[metric_name_1]\n",
        "    metric_value_2 = model_training_history.history[metric_name_2]\n",
        "\n",
        "    # Construct a range object which will be used as x-axis (horizontal plane) of the graph.\n",
        "    epochs = range(len(metric_value_1))\n",
        "\n",
        "    plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
        "    plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
        "\n",
        "\n",
        "    plt.title(str(plot_name))\n",
        "\n",
        "    # Add legend to the plot.\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmU2Hs1hMRlZ"
      },
      "outputs": [],
      "source": [
        "plot_metric(convlstm_model_training_history, 'loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hn9eyKHXMRob"
      },
      "outputs": [],
      "source": [
        "plot_metric(convlstm_model_training_history, 'accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gxBhZgh4CvK"
      },
      "outputs": [],
      "source": [
        "y_pred = np.argmax(convlstm_model.predict(features_test),axis=1)\n",
        "y_test  = np.argmax(labels_test,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUVvaLMK4ydx"
      },
      "outputs": [],
      "source": [
        "y_pred,y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuO-5p9T5K3k"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay,confusion_matrix,f1_score,precision_score,recall_score,classification_report\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred,display_labels=CLASSES_LIST,xticks_rotation='vertical')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNvnOaVQ5pP6"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, y_pred,target_names=CLASSES_LIST))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cscizjUdtJ3M"
      },
      "outputs": [],
      "source": [
        "!pip install mediapy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpLLGhYStkuB"
      },
      "outputs": [],
      "source": [
        "def frames_extraction(video_path):\n",
        "    '''\n",
        "    This function will extract the required frames from a video after resizing and normalizing them.\n",
        "    Args:\n",
        "        video_path: The path of the video in the disk, whose frames are to be extracted.\n",
        "    Returns:\n",
        "        frames_list: A list containing the resized and normalized frames of the video.\n",
        "    '''\n",
        "\n",
        "    # Declare a list to store video frames.\n",
        "    frames_list = []\n",
        "\n",
        "    # Read the Video File using the VideoCapture object.\n",
        "    video_reader = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Get the total number of frames in the video.\n",
        "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Calculate the the interval after which frames will be added to the list.\n",
        "    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH), 1)\n",
        "\n",
        "    # Iterate through the Video Frames.\n",
        "    for frame_counter in range(SEQUENCE_LENGTH):\n",
        "\n",
        "        # Set the current frame position of the video.\n",
        "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
        "\n",
        "        # Reading the frame from the video.\n",
        "        success, frame = video_reader.read()\n",
        "\n",
        "        # Check if Video frame is not successfully read then break the loop\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        # Resize the Frame to fixed height and width.\n",
        "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "\n",
        "        # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1\n",
        "        normalized_frame = resized_frame / 255\n",
        "\n",
        "        # Append the normalized frame into the frames list\n",
        "        frames_list.append(normalized_frame)\n",
        "\n",
        "    # Release the VideoCapture object.\n",
        "    video_reader.release()\n",
        "\n",
        "    # Return the frames list.\n",
        "    return frames_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LToQD9XWr124"
      },
      "outputs": [],
      "source": [
        "CLASSES_LIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qS7aGlOEq1l7"
      },
      "outputs": [],
      "source": [
        "def vid_class_pred(path,class_list):\n",
        "    arr = np.array(frames_extraction(path))\n",
        "    arr = np.expand_dims(arr, axis=0)\n",
        "    model_pred = convlstm_model.predict(arr).ravel()\n",
        "    pred_prob = max(model_pred)\n",
        "    pred_class = class_list[np.argmax(model_pred)]\n",
        "    return pred_class,pred_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoEt2OA-5lus"
      },
      "outputs": [],
      "source": [
        "lst=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCAoDSpOtIuu"
      },
      "outputs": [],
      "source": [
        "import mediapy as media\n",
        "vid_path = '/content/video_data/Robbery/Robbery056_x264_1.mp4'\n",
        "\n",
        "video = media.read_video(vid_path)\n",
        "pred,prob = vid_class_pred(vid_path,CLASSES_LIST)\n",
        "lst.append((pred,prob))\n",
        "media.show_video(video, fps=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YC6O6seVqBTz"
      },
      "outputs": [],
      "source": [
        "for i in lst:\n",
        "  print(i[0],'\\t',i[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diwIA_2-6lD-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df= pd.DataFrame(lst,columns=['pred','prob'])\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6md5HeVAzsvE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}